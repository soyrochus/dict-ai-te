# Prompt: Refactor `dict-ai-te` for pluggable UIs and add a Flask web UI

## Goal

Refactor the existing `dict-ai-te` desktop app so the UI is fully decoupled from the core logic, then add an optional web interface (Flask) that reuses the same backend services and mirrors the GTK UI and behavior. The web UI must support audio recording, audio testing, playback, transcription via OpenAI Whisper, optional translation, copy/download, and settings.

## Inputs you have

* Project README describing current features and environment.
* Current GTK4/PyGObject app code.
* Two reference images for layout parity:

  * `design/main-window.png` (or provided as `main-window.png`)
  * `design/settings-panel.png` (or provided as `settings-panel.png`)
* Text to insert in the web UI about section or footer: `XXX`.

## Deliverables

1. A clean architecture split with a shared backend service layer.
2. A Flask web app providing the same functionality and layout as the GTK app.
3. Build and run scripts, tests, and migration notes.
4. Minimal docs: `ARCHITECTURE.md` and `WEBUI.md`.

## Non-functional constraints

* Python 3.12+ where possible.
* Keep dependencies minimal. For the web, use Flask + vanilla JS; no heavy frontend frameworks.
* Audio: in the browser use MediaRecorder + WebAudio; on desktop keep current PortAudio pipeline.
* Cross-platform: Linux, macOS, Windows. 
* Keep OpenAI keys in env vars or `.env` as today.
* MIT license preserved.

---

## 1) Target architecture

Introduce a package `dictaite.core` that has **no GUI imports**.
Reactor everyting so there are 3 modules
1 for the GtK UI
1 for the Web UI/backend
1 for the transcrition/AI etc logic (reuseing existing funcionality)

### Service layer API (to be used by both UIs)

```python
# dictaite_core/services/stt.py
def transcribe(audio: bytes, mimetype: str, language: str | None) -> str: ...

# dictaite_core/services/translate.py
def translate(text: str, target_lang: str) -> str: ...

# dictaite_core/config.py
@dataclass
class Settings:
    default_language: str | None  # auto-detect if None
    translate_by_default: bool
    default_target_language: str | None
    female_voice: str             # e.g., "Nova"
    male_voice: str               # e.g., "Onyx"
```

Use OpenAI Whisper transcription as today. Keep translation via the same provider you currently use.

---

## 2) Flask web app requirements

### Routes

* `GET /` → main page (recording UI).
* `GET /settings` → settings panel UI.
* `POST /api/transcribe`

  * Body: `multipart/form-data` with `audio` (blob), `language` (optional), `translate` (bool), `target_lang` (optional).
  * Response: `{ text, translatedText?, durationMs }`.
* `POST /api/tts-test` (optional voice test)

  * Body: `{ gender: "female"|"male", text }`.
  * Response: audio bytes (set `Content-Type: audio/wav`).
* `GET /api/health` → `{ ok: true }`.

### Security and ops

* Read OpenAI key from env or `.env`.
* Limit uploads to ≤ 2 min and accepted mime types `audio/webm`, `audio/wav`, `audio/ogg`.
* Use Flask app factory pattern and Blueprints.
* Add CORS disabled by default.
* Add simple rate limit placeholder (document where to plug in).

### Browser audio handling

* Use `navigator.mediaDevices.getUserMedia({ audio: true })`.
* Record with `MediaRecorder`. Store chunks, `onstop` assemble a Blob.
* Show real-time level meter using WebAudio `AnalyserNode`.
* Provide controls: Record/Stop, Play, Copy, Download, Clear.
* Provide a small elapsed time display and a status bar.

### UI layout parity

Replicate the GTK layout from the two images.

**Main window (`index.html`)**

* Header row: app title left, **Settings** button right.
* Central panel: large microphone icon that toggles recording state.

  * Below: “Press to start recording” label and `00:00:00` timer.
* “Origin language” dropdown.
* “Translate to” toggle; when on, show “Destination language” dropdown.
* Text area for transcript.
* Bottom action row: Download, Copy, Play, Record gender selector (Female/Male).
* Keyboard shortcuts:

  * `Space` → start/stop recording when focus not in textarea.
  * `Ctrl/Cmd+C` → copy transcript.
  * `Ctrl/Cmd+S` → download transcript `.txt`.

**Settings panel (`settings.html`)**

* Default language dropdown (“Default — Auto-detect”).
* “Translate by default” toggle.
* “Default target language” dropdown.
* Female voice select with “Play” button.
* Male voice select with “Play” button.
* Footer note: include `XXX`.
* Buttons: **Cancel** (link back), **Save** (POST to `/api/settings` or store in localStorage if you prefer client-side).

Match spacing, labels, and order shown in `main-window.png` and `settings-panel.png`. Use simple CSS grid and system fonts. Use tailwind.css for layout.

### Client–server flow

1. On stop recording, `app.js` posts the audio blob to `/api/transcribe` with chosen language and flags.
2. Server saves blob to temp, runs `dictaite_core.services.stt.transcribe`, optionally runs translate, returns JSON.
3. Client fills the textarea with the returned text (and translated text when applicable).
4. Play button either replays the recorded blob or calls `/api/tts-test` to synthesize a test phrase using the selected voice. Document which you implement.

---

## 3) GTK app adjustments

* Replace any direct OpenAI calls in UI code with calls to `dictaite_core.services.*`.
* Ensure GUI code has zero imports from `openai` or other provider SDKs.
* Keep the same behavior and labels as today.

---

## 4) Implementation details

### Packaging

* Keep `pyproject.toml` and add optional extras:

  * `ui-gtk`: `["PyGObject"]` (install the PortAudio system library separately)
  * `ui-web`: `["flask", "python-dotenv"]`
* CLI scripts:

  * `bin/dictaite` → launches GTK UI.
  * `bin/dictaite-web` → `FLASK_ENV=production python -m ui_web.app` with `--host 0.0.0.0 --port 5000`.

### MIME and formats

* Prefer WAV PCM 16-bit server-side for Whisper accuracy. If MediaRecorder yields `webm/ogg`, transcode to WAV using `pydub` or `soundfile`. Keep it minimal.

### Errors

* Standard JSON error schema: `{ "error": { "code": "...", "message": "..." } }` with proper HTTP codes.

### Tests

* Unit tests for `transcribe()` and `translate()` using short fixtures.
* API test: `POST /api/transcribe` with a tiny WAV fixture.
* Lightweight Playwright or pytest-playwright smoke for recording controls is a plus; otherwise document manual steps.

---

## 5) Definition of Done

* GTK app runs unchanged in behavior, now importing only `dictaite_core`.
* Flask app runs with `bin/dictaite-web`, serves `index.html` and `settings.html`, and mirrors the GTK layout and features shown in the two images.
* Browser recording, playback, transcription and optional translation all work end-to-end.
* Users can copy and download transcripts.
* Settings persist for the session; if feasible, save to a small JSON in `~/.dictaite/settings.json`, else use localStorage and document it.
* `ARCHITECTURE.md` explains layers, contracts, and how to add future UIs.
* `WEBUI.md` explains how to run the Flask app and browser permissions.
* Lint passes; tests green.

---

## 6) Migration notes for the agent to generate

* Move current business logic into `dictaite_core`.
* Replace any blocking I/O in services with async if trivial; otherwise keep sync and run in threadpool on the web side.
* Keep public service function signatures stable and documented.
* Add minimal logging with `logging` module.

---

## 7) Out of scope

* Heavy frontend frameworks.
* Multi-user auth.
* Cloud deployment scripts beyond a simple `gunicorn` note in `WEBUI.md`.

---

**Execute the refactor and web UI creation as above. Produce code, tests, and docs. Keep the UI texts and control order identical to the GTK app unless infeasible in the browser.**
